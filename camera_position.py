import cv2
import numpy as np
import time
import tkinter as tk
from tkinter import simpledialog
from datetime import datetime
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
from collections import deque
import threading

# Raspberry Pi ì¹´ë©”ë¼ ì§€ì› (picamera2)
try:
    from picamera2 import Picamera2
    USE_PICAMERA2 = True
except ImportError:
    USE_PICAMERA2 = False
    print("[INFO] picamera2 not found, using standard camera")   

# ===== ì„¤ì • =====
SOURCE = 0  # 0=ì›¹ìº 
FONT = cv2.FONT_HERSHEY_SIMPLEX

# ===== ì „ì—­ ë³€ìˆ˜ =====
FIXED_Z_DISTANCE = 0.032  # 3.2cm = 0.032m (ê¸°ë³¸ê°’)
focal_length = 800.0  # ì´ˆì ê±°ë¦¬ (ê¸°ë³¸ê°’, ìë™ ì¡°ì •ë¨)

selected_points = []  # ì„ íƒí•œ 3ì ì˜ ì´ˆê¸° í”½ì…€ ì¢Œí‘œ
point_names = ['Point 1', 'Point 2', 'Point 3']
tracked_points = []  # ì¶”ì  ì¤‘ì¸ ì ë“¤ (ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸)

tracking_active = False

# ì¸¡ì • ê´€ë ¨ ë³€ìˆ˜
measurement_active = False
last_measurement_time = 0
measurement_log = []  # ì¸¡ì • ê¸°ë¡ ì €ì¥

# ê·¸ë˜í”„ ê´€ë ¨ ë³€ìˆ˜
graph_enabled = False
graph_data_time = deque(maxlen=100)  # ìµœê·¼ 100ê°œ ë°ì´í„°ë§Œ ìœ ì§€
graph_data_p1 = deque(maxlen=100)
graph_data_p2 = deque(maxlen=100)
graph_data_p3 = deque(maxlen=100)
graph_start_time = None
graph_lock = threading.Lock()

def get_z_distance_input():
    """Zì¶• ê±°ë¦¬ ì…ë ¥ ë°›ê¸°"""
    root = tk.Tk()
    root.withdraw()
    
    distance_cm = simpledialog.askfloat(
        "Zì¶• ê±°ë¦¬ ì„¤ì •",
        "ì¹´ë©”ë¼ì™€ ë¬¼ì²´ ì‚¬ì´ì˜ Zì¶• ê±°ë¦¬ë¥¼ ì…ë ¥í•˜ì„¸ìš” (cm ë‹¨ìœ„):\n\n"
        "ì˜ˆ: 3.2 (3.2cm)\n"
        "    5.0 (5cm)\n"
        "    10.0 (10cm)",
        initialvalue=3.2,
        minvalue=0.1,
        maxvalue=1000.0
    )
    
    root.destroy()
    
    if distance_cm is not None:
        return distance_cm / 100.0  # cmë¥¼ më¡œ ë³€í™˜
    return None

def calculate_3d_position_fixed_z(point_px, focal_length, fixed_z, image_width, image_height):
    """
    ê³ ì •ëœ Z ê±°ë¦¬ë¡œ 3D ìœ„ì¹˜ ê³„ì‚°
    
    Args:
        point_px: (x, y) í”½ì…€ ì¢Œí‘œ
        focal_length: ì´ˆì ê±°ë¦¬
        fixed_z: ê³ ì •ëœ Zì¶• ê±°ë¦¬ (ë¯¸í„°)
        image_width, image_height: ì´ë¯¸ì§€ í¬ê¸°
    
    Returns:
        (X, Y, Z, distance_3d)
    """
    cx = image_width / 2.0
    cy = image_height / 2.0
    
    # í”½ì…€ ì¢Œí‘œë¥¼ ì •ê·œí™”
    x_norm = (point_px[0] - cx) / focal_length
    y_norm = (point_px[1] - cy) / focal_length
    
    # 3D ìœ„ì¹˜ (ZëŠ” ê³ ì •)
    Z = fixed_z
    X = x_norm * Z
    Y = y_norm * Z
    
    # ì¹´ë©”ë¼ë¡œë¶€í„°ì˜ ìœ í´ë¦¬ë“œ ê±°ë¦¬
    distance_3d = np.sqrt(X**2 + Y**2 + Z**2)
    
    return X, Y, Z, distance_3d

def calculate_alignment_metrics(points_3d):
    """
    3ê°œ ì ì˜ ì •ë ¬ ìƒíƒœë¥¼ ì¸¡ì •
    
    Args:
        points_3d: [(X1, Y1, Z1), (X2, Y2, Z2), (X3, Y3, Z3)]
    
    Returns:
        dict: {
            'z_std': Zì¶• í‘œì¤€í¸ì°¨,
            'z_range': Zì¶• ìµœëŒ€-ìµœì†Œ ì°¨ì´,
            'collinearity': ê³µì„ ì„± ì •ë„ (0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¼ì§ì„ ),
            'is_aligned': ì •ë ¬ ì—¬ë¶€ (bool)
        }
    """
    if len(points_3d) != 3:
        return None
    
    # Zì¶• ë¶„ì„
    z_values = [p[2] for p in points_3d]
    z_std = np.std(z_values)
    z_range = max(z_values) - min(z_values)
    
    # ê³µì„ ì„± ì¸¡ì • (3ì ì´ ì¼ì§ì„ ìƒì— ìˆëŠ”ì§€)
    # ë²¡í„° ABì™€ ACë¥¼ êµ¬í•˜ê³  ì™¸ì (cross product)ì˜ í¬ê¸°ë¥¼ ê³„ì‚°
    p1, p2, p3 = points_3d
    vec_AB = np.array([p2[0] - p1[0], p2[1] - p1[1], p2[2] - p1[2]])
    vec_AC = np.array([p3[0] - p1[0], p3[1] - p1[1], p3[2] - p1[2]])
    
    # ì™¸ì ì˜ í¬ê¸° (0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¼ì§ì„ )
    cross_product = np.cross(vec_AB, vec_AC)
    collinearity = np.linalg.norm(cross_product)
    
    # ì •ê·œí™” (ê±°ë¦¬ ê¸°ì¤€)
    distance_AB = np.linalg.norm(vec_AB)
    distance_AC = np.linalg.norm(vec_AC)
    if distance_AB > 0 and distance_AC > 0:
        collinearity_normalized = collinearity / (distance_AB * distance_AC)
    else:
        collinearity_normalized = 0
    
    # ì •ë ¬ íŒì • ê¸°ì¤€
    # Zì¶• ë²”ìœ„ê°€ 1mm ì´ë‚´ì´ê³ , ê³µì„ ì„±ì´ ë‚®ìœ¼ë©´ ì •ë ¬ëœ ê²ƒìœ¼ë¡œ íŒì •
    is_aligned = (z_range < 0.001) and (collinearity_normalized < 0.05)
    
    return {
        'z_std': z_std,
        'z_range': z_range,
        'collinearity': collinearity,
        'collinearity_normalized': collinearity_normalized,
        'is_aligned': is_aligned
    }

def mouse_callback(event, x, y, flags, param):
    """ë§ˆìš°ìŠ¤ í´ë¦­ìœ¼ë¡œ 3ì  ì„ íƒ"""
    global selected_points, tracked_points, tracking_active, measurement_active, last_measurement_time
    
    if event == cv2.EVENT_LBUTTONDOWN and not tracking_active:
        if len(selected_points) < 3:
            selected_points.append((x, y))
            tracked_points.append((x, y))
            print(f"[INFO] {point_names[len(selected_points)-1]} ì„ íƒ: ({x}, {y})")
            
            if len(selected_points) == 3:
                tracking_active = True
                measurement_active = True  # ìë™ìœ¼ë¡œ ì¸¡ì • ì‹œì‘
                last_measurement_time = time.time()
                print("[INFO] 3ì  ì„ íƒ ì™„ë£Œ! ì‹¤ì‹œê°„ ì¶”ì  ë° ì¸¡ì • ìë™ ì‹œì‘")

def track_points_optical_flow(prev_gray, curr_gray, points):
    """
    Optical Flowë¡œ ì  ì¶”ì 
    
    Args:
        prev_gray: ì´ì „ í”„ë ˆì„ (grayscale)
        curr_gray: í˜„ì¬ í”„ë ˆì„ (grayscale)
        points: ì¶”ì í•  ì ë“¤
    
    Returns:
        ì¶”ì ëœ ì ë“¤ ë˜ëŠ” None
    """
    if points is None or len(points) == 0:
        return None
    
    # Lucas-Kanade Optical Flow íŒŒë¼ë¯¸í„°
    lk_params = dict(
        winSize=(15, 15),
        maxLevel=2,
        criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)
    )
    
    # numpy arrayë¡œ ë³€í™˜
    points_array = np.array(points, dtype=np.float32).reshape(-1, 1, 2)
    
    # Optical Flow ê³„ì‚°
    next_points, status, error = cv2.calcOpticalFlowPyrLK(
        prev_gray, curr_gray, points_array, None, **lk_params
    )
    
    if next_points is None:
        return None
    
    # ì„±ê³µì ìœ¼ë¡œ ì¶”ì ëœ ì ë“¤ë§Œ ë°˜í™˜
    good_points = []
    for i, (st, pt) in enumerate(zip(status, next_points)):
        if st == 1:  # ì¶”ì  ì„±ê³µ
            good_points.append(tuple(pt.ravel()))
        else:
            # ì¶”ì  ì‹¤íŒ¨ ì‹œ ì´ì „ ìœ„ì¹˜ ìœ ì§€
            good_points.append(points[i])
    
    return good_points

def update_graph_data(distances_cm):
    """
    ê·¸ë˜í”„ ë°ì´í„° ì—…ë°ì´íŠ¸
    
    Args:
        distances_cm: [dist1, dist2, dist3] (cm ë‹¨ìœ„)
    """
    global graph_data_time, graph_data_p1, graph_data_p2, graph_data_p3
    global graph_start_time, graph_lock
    
    if graph_start_time is None:
        graph_start_time = time.time()
    
    elapsed_time = time.time() - graph_start_time
    
    with graph_lock:
        graph_data_time.append(elapsed_time)
        graph_data_p1.append(distances_cm[0])
        graph_data_p2.append(distances_cm[1])
        graph_data_p3.append(distances_cm[2])

def create_realtime_graph():
    """ì‹¤ì‹œê°„ ê·¸ë˜í”„ ì°½ ìƒì„± ë° ì—…ë°ì´íŠ¸"""
    global graph_enabled
    
    # matplotlib ì„¤ì •
    try:
        plt.style.use('seaborn-v0_8-darkgrid')
    except:
        try:
            plt.style.use('seaborn-darkgrid')
        except:
            pass  # ê¸°ë³¸ ìŠ¤íƒ€ì¼ ì‚¬ìš©
    
    fig, ax = plt.subplots(figsize=(10, 6))
    
    line1, = ax.plot([], [], 'b-', linewidth=2, label='Point 1', marker='o', markersize=3)
    line2, = ax.plot([], [], 'g-', linewidth=2, label='Point 2', marker='s', markersize=3)
    line3, = ax.plot([], [], 'r-', linewidth=2, label='Point 3', marker='^', markersize=3)
    
    ax.set_xlabel('Time (seconds)', fontsize=12)
    ax.set_ylabel('Distance (cm)', fontsize=12)
    ax.set_title('Real-time Distance Tracking (3 Points)', fontsize=14, fontweight='bold')
    ax.legend(loc='upper right')
    ax.grid(True, alpha=0.3)
    
    def init():
        ax.set_xlim(0, 10)
        ax.set_ylim(0, 10)
        return line1, line2, line3
    
    def update(frame):
        global graph_data_time, graph_data_p1, graph_data_p2, graph_data_p3
        
        with graph_lock:
            if len(graph_data_time) > 0:
                times = list(graph_data_time)
                p1_data = list(graph_data_p1)
                p2_data = list(graph_data_p2)
                p3_data = list(graph_data_p3)
                
                line1.set_data(times, p1_data)
                line2.set_data(times, p2_data)
                line3.set_data(times, p3_data)
                
                # ì¶• ë²”ìœ„ ìë™ ì¡°ì •
                if len(times) > 0:
                    ax.set_xlim(max(0, times[-1] - 30), times[-1] + 2)  # ìµœê·¼ 30ì´ˆ
                    
                    all_distances = p1_data + p2_data + p3_data
                    if all_distances:
                        min_dist = min(all_distances)
                        max_dist = max(all_distances)
                        margin = (max_dist - min_dist) * 0.1 or 1
                        ax.set_ylim(min_dist - margin, max_dist + margin)
        
        return line1, line2, line3
    
    ani = FuncAnimation(fig, update, init_func=init, blit=True, interval=100, cache_frame_data=False)
    
    plt.tight_layout()
    plt.show()
    
    graph_enabled = False
    print("[INFO] ê·¸ë˜í”„ ì°½ì´ ë‹«í˜”ìŠµë‹ˆë‹¤.")

def start_graph_thread():
    """ê·¸ë˜í”„ë¥¼ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰ (Linux/Raspberry Piì—ì„œ ì œí•œì  ì§€ì›)"""
    global graph_enabled, graph_start_time
    global graph_data_time, graph_data_p1, graph_data_p2, graph_data_p3
    
    if graph_enabled:
        print("[WARNING] ê·¸ë˜í”„ê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.")
        return
    
    # matplotlib ìŠ¤ë ˆë“œ ì•ˆì „ì„± ê²½ê³ 
    print("[WARNING] matplotlib ê·¸ë˜í”„ëŠ” ë©”ì¸ ìŠ¤ë ˆë“œ ë¬¸ì œë¡œ ì¸í•´ ì œí•œì ìœ¼ë¡œ ì‘ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    print("[INFO] ëŒ€ì‹  's' í‚¤ë¥¼ ëˆŒëŸ¬ CSV íŒŒì¼ë¡œ ì €ì¥ í›„, ë³„ë„ë¡œ ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
    print("[INFO] ê·¸ë˜í”„ ê¸°ëŠ¥ì„ ì‹œë„í•©ë‹ˆë‹¤...")
    
    # ê·¸ë˜í”„ ë°ì´í„° ì´ˆê¸°í™”
    graph_start_time = time.time()
    with graph_lock:
        graph_data_time.clear()
        graph_data_p1.clear()
        graph_data_p2.clear()
        graph_data_p3.clear()
    
    graph_enabled = True
    
    # ìŠ¤ë ˆë“œ ëŒ€ì‹  ë³„ë„ í”„ë¡œì„¸ìŠ¤ ì‚¬ìš© ì‹œë„
    try:
        graph_thread = threading.Thread(target=create_realtime_graph, daemon=True)
        graph_thread.start()
        print("[INFO] ì‹¤ì‹œê°„ ê·¸ë˜í”„ ì‹œì‘ (ë³„ë„ ì°½)")
    except Exception as e:
        print(f"[ERROR] ê·¸ë˜í”„ ì‹œì‘ ì‹¤íŒ¨: {e}")
        print("[INFO] CSV ì €ì¥ ê¸°ëŠ¥('s' í‚¤)ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        graph_enabled = False

def save_measurement_log():
    """ì¸¡ì • ê¸°ë¡ì„ CSV íŒŒì¼ë¡œ ì €ì¥"""
    if not measurement_log:
        print("\n" + "="*70)
        print("[INFO] ì €ì¥í•  ì¸¡ì • ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        print("\nì¸¡ì • ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ë°©ë²•:")
        print("  1. í™”ë©´ì—ì„œ ë§ˆìš°ìŠ¤ë¡œ 3ì ì„ í´ë¦­í•˜ì„¸ìš”")
        print("  2. 3ì  ì„ íƒ í›„ ìë™ìœ¼ë¡œ 1ì´ˆë§ˆë‹¤ ì¸¡ì •ì´ ì‹œì‘ë©ë‹ˆë‹¤")
        print("  3. ì¸¡ì •ì´ ì§„í–‰ë˜ëŠ” ë™ì•ˆ 's' í‚¤ë¥¼ ëˆŒëŸ¬ ì €ì¥í•˜ì„¸ìš”")
        print("  4. ë˜ëŠ” 'm' í‚¤ë¡œ ì¸¡ì •ì„ ì‹œì‘/ì¤‘ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        print("="*70 + "\n")
        return
    
    filename = f"distance_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
    with open(filename, 'w', encoding='utf-8') as f:
        # í—¤ë”
        f.write("Timestamp,Point1_X(cm),Point1_Y(cm),Point1_Z(cm),Point1_Distance(cm),")
        f.write("Point2_X(cm),Point2_Y(cm),Point2_Z(cm),Point2_Distance(cm),")
        f.write("Point3_X(cm),Point3_Y(cm),Point3_Z(cm),Point3_Distance(cm),")
        f.write("Z_Range(mm),Collinearity,Aligned\n")
        
        # ë°ì´í„°
        for entry in measurement_log:
            f.write(f"{entry['timestamp']},")
            for i in range(3):
                pt = entry['points'][i]
                f.write(f"{pt['X']:.2f},{pt['Y']:.2f},{pt['Z']:.2f},{pt['distance']:.2f},")
            
            # ì •ë ¬ ì •ë³´ ì¶”ê°€
            if 'alignment' in entry and entry['alignment'] is not None:
                align = entry['alignment']
                f.write(f"{align['z_range']*1000:.2f},")  # mmë¡œ ë³€í™˜
                f.write(f"{align['collinearity_normalized']:.4f},")
                f.write(f"{'YES' if align['is_aligned'] else 'NO'}")
            else:
                f.write("N/A,N/A,N/A")
            
            f.write("\n")
    
    print("\n" + "="*70)
    print(f"âœ“ ì¸¡ì • ë°ì´í„° ì €ì¥ ì™„ë£Œ!")
    print(f"  íŒŒì¼ëª…: {filename}")
    print(f"  ê¸°ë¡ ìˆ˜: {len(measurement_log)}ê°œ")
    print(f"  3ì  ê±°ë¦¬ ë°ì´í„° (X, Y, Z ì¢Œí‘œ ë° ì •ë ¬ ìƒíƒœ í¬í•¨)")
    print("="*70 + "\n")

def main():
    global FIXED_Z_DISTANCE, focal_length
    global selected_points, tracked_points, tracking_active
    global measurement_active, last_measurement_time, measurement_log
    
    # Zì¶• ê±°ë¦¬ ì„¤ì •
    print("[INFO] Zì¶• ê±°ë¦¬ ì„¤ì •...")
    z_input = get_z_distance_input()
    
    if z_input is not None:
        FIXED_Z_DISTANCE = z_input
        print(f"[INFO] Zì¶• ê±°ë¦¬ ì„¤ì •: {FIXED_Z_DISTANCE*100:.1f}cm ({FIXED_Z_DISTANCE:.4f}m)")
    else:
        print(f"[INFO] ê¸°ë³¸ê°’ ì‚¬ìš©: {FIXED_Z_DISTANCE*100:.1f}cm")
    
    print("[INFO] ì¹´ë©”ë¼ ì´ˆê¸°í™” ì¤‘...")
    
    # ì¹´ë©”ë¼ ì´ˆê¸°í™”
    picam = None
    cap = None
    
    # Raspberry Pi ì¹´ë©”ë¼ ì‹œë„ (picamera2)
    if USE_PICAMERA2:
        try:
            print("[INFO] Raspberry Pi ì¹´ë©”ë¼(picamera2) ì´ˆê¸°í™” ì¤‘...")
            
            picam = Picamera2()
            
            # ë¹„ë””ì˜¤ ì„¤ì • ìƒì„± (BGR888 í¬ë§·ìœ¼ë¡œ OpenCVì™€ í˜¸í™˜)
            config = picam.create_video_configuration(
                main={"size": (1280, 720), "format": "BGR888"},
                controls={"FrameRate": 30}
            )
            picam.configure(config)
            
            # ì¹´ë©”ë¼ ì‹œì‘
            picam.start()
            
            print("[INFO] ì¹´ë©”ë¼ ì›Œë°ì—… ì¤‘... (2ì´ˆ)")
            time.sleep(2)  # ì¹´ë©”ë¼ ì›Œë°ì—…
            
            # í…ŒìŠ¤íŠ¸ í”„ë ˆì„ ìº¡ì²˜
            test_frame = picam.capture_array()
            
            if test_frame is not None and test_frame.size > 0:
                h, w = test_frame.shape[:2]
                print(f"[SUCCESS] Raspberry Pi ì¹´ë©”ë¼ ì´ˆê¸°í™” ì™„ë£Œ!")
                print(f"  í•´ìƒë„: {w}x{h}")
                print(f"  í¬ë§·: BGR888")
                print(f"  ë¼ì´ë¸ŒëŸ¬ë¦¬: picamera2")
            else:
                print("[ERROR] í…ŒìŠ¤íŠ¸ í”„ë ˆì„ ìº¡ì²˜ ì‹¤íŒ¨")
                picam.stop()
                picam.close()
                picam = None
                
        except Exception as e:
            print(f"[ERROR] Raspberry Pi ì¹´ë©”ë¼ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            print(f"  ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
            print("\ní•´ê²° ë°©ë²•:")
            print("  1. ì¹´ë©”ë¼ ì¼€ì´ë¸” ì—°ê²° í™•ì¸")
            print("  2. libcameraê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸:")
            print("     sudo apt install -y python3-picamera2")
            print("  3. ì¹´ë©”ë¼ê°€ ê°ì§€ë˜ëŠ”ì§€ í™•ì¸:")
            print("     libcamera-hello --list-cameras")
            print("  4. ì¬ë¶€íŒ…: sudo reboot")
            
            if picam is not None:
                try:
                    picam.stop()
                    picam.close()
                except:
                    pass
            picam = None
            print("[INFO] USB ì¹´ë©”ë¼ë¡œ ìë™ ì „í™˜í•©ë‹ˆë‹¤...\n")
    
    # USB ì¹´ë©”ë¼ ì‚¬ìš© (picameraê°€ ì—†ê±°ë‚˜ ì‹¤íŒ¨í•œ ê²½ìš°)
    if picam is None:
        print("[INFO] USB ì¹´ë©”ë¼ ì‚¬ìš©")
        cap = cv2.VideoCapture(SOURCE)
        if not cap.isOpened():
            print("[ERROR] USB ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            print("[INFO] ë‹¤ë¥¸ ì¹´ë©”ë¼ ì¸ë±ìŠ¤ ì‹œë„ ì¤‘...")
            # ë‹¤ë¥¸ ì¹´ë©”ë¼ ì¸ë±ìŠ¤ ì‹œë„
            for i in range(1, 4):
                cap = cv2.VideoCapture(i)
                if cap.isOpened():
                    print(f"[INFO] ì¹´ë©”ë¼ ì¸ë±ìŠ¤ {i}ì—ì„œ ì¹´ë©”ë¼ ë°œê²¬!")
                    break
            
            if not cap.isOpened():
                print("[ERROR] ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
                print("\ní•´ê²° ë°©ë²•:")
                print("1. Raspberry Pi ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´:")
                print("   sudo raspi-config -> Interface Options -> Camera -> Enable")
                print("2. USB ì¹´ë©”ë¼ê°€ ì œëŒ€ë¡œ ì—°ê²°ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”:")
                print("   ls /dev/video*")
                return
        
        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
        
        for _ in range(5):
            cap.read()
            time.sleep(0.1)
        
        ret, test_frame = cap.read()
        if not ret or test_frame is None:
            print("[ERROR] ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            cap.release()
            return
        
        print(f"[INFO] USB ì¹´ë©”ë¼ ì´ˆê¸°í™” ì„±ê³µ! í•´ìƒë„: {test_frame.shape[1]}x{test_frame.shape[0]}")
    
    # ì°½ ìƒì„±
    window_name = "Fixed Z-Axis Distance Tracker"
    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
    cv2.resizeWindow(window_name, 1280, 720)
    cv2.setMouseCallback(window_name, mouse_callback)
    
    print("\n" + "="*70)
    print(" Fixed Z-Axis Distance Tracker with Alignment Detection")
    print("="*70)
    print(f"\nì„¤ì •: Zì¶• ê³ ì • ê±°ë¦¬ = {FIXED_Z_DISTANCE*100:.1f}cm")
    print("\nì‚¬ìš©ë²•:")
    print("  1. ë§ˆìš°ìŠ¤ë¡œ 3ì ì„ í´ë¦­í•˜ì—¬ ì„ íƒ")
    print("  2. ìë™ìœ¼ë¡œ ì‹¤ì‹œê°„ ì¶”ì  ë° ì¸¡ì • ì‹œì‘ (1ì´ˆë§ˆë‹¤ ìë™ ê¸°ë¡)")
    print("  3. ì¹´ë©”ë¼ë¥¼ ì¢Œìš°ë¡œ ì›€ì§ì´ë©´ ê° ì ê³¼ì˜ ê±°ë¦¬ê°€ ì‹¤ì‹œê°„ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤")
    print("  4. ì˜¤ë¥¸ìª½ ìƒë‹¨ì—ì„œ 3ì ì˜ ì •ë ¬ ìƒíƒœë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
    print("  5. 's' í‚¤ë¥¼ ëˆŒëŸ¬ ì¸¡ì • ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥")
    print("\nì •ë ¬ ì¸¡ì • í•­ëª©:")
    print("  - Z-axis range: 3ì ì˜ Zì¶• í¸ì°¨ (1mm ì´í•˜ë©´ ë…¹ìƒ‰)")
    print("  - Collinearity: 3ì ì˜ ì¼ì§ì„  ì •ë„ (0.05 ì´í•˜ë©´ ë…¹ìƒ‰)")
    print("  - Status: ALIGNED (ë…¹ìƒ‰ ì²´í¬) ë˜ëŠ” NOT ALIGNED (ë¹¨ê°„ìƒ‰ X)")
    print("\në‹¨ì¶•í‚¤:")
    print("  'm' - ì¸¡ì • ì‹œì‘/ì¤‘ì§€ (ê¸°ë³¸: ìë™ ì‹œì‘)")
    print("  's' - ì¸¡ì • ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥ (ì¤‘ìš”!)")
    print("  'g' - ì‹¤ì‹œê°„ ê·¸ë˜í”„ í‘œì‹œ (3ì ì˜ ê±°ë¦¬ vs ì‹œê°„, ì œí•œì )")
    print("  'r' - ì  ì„ íƒ ì´ˆê¸°í™” (ë‹¤ì‹œ ì„ íƒ)")
    print("  'z' - Zì¶• ê±°ë¦¬ ì¬ì„¤ì •")
    print("  'q' - ì¢…ë£Œ (ìë™ìœ¼ë¡œ ë°ì´í„° ì €ì¥)")
    print("="*70)
    print("\nğŸ’¡ íŒ: 3ì  ì„ íƒ í›„ ìë™ìœ¼ë¡œ ì¸¡ì •ì´ ì‹œì‘ë˜ë©°, ì¢…ë£Œ ì‹œ ìë™ ì €ì¥ë©ë‹ˆë‹¤!")
    print("="*70 + "\n")
    
    # EMA í•„í„° (ë¶€ë“œëŸ¬ìš´ ì¶œë ¥)
    alpha = 0.3
    ema_distances = [None, None, None]
    
    # Optical Flowìš© ì´ì „ í”„ë ˆì„
    prev_gray = None
    
    h_img, w_img = test_frame.shape[:2]
    
    # picamera2ëŠ” ìŠ¤íŠ¸ë¦¬ë° ì„¤ì •ì´ í•„ìš” ì—†ìŒ (ì´ë¯¸ start()ë¡œ ì‹œì‘ë¨)
    if picam is not None:
        print("[INFO] Raspberry Pi ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¬ë° ì¤€ë¹„ ì™„ë£Œ")
    
    while True:
        # í”„ë ˆì„ ì½ê¸°
        if picam is not None:
            try:
                # picamera2ë¡œ í”„ë ˆì„ ìº¡ì²˜ (BGR888 í¬ë§·)
                frame = picam.capture_array()
                
                if frame is None or frame.size == 0:
                    time.sleep(0.01)
                    continue
            except Exception as e:
                print(f"[ERROR] í”„ë ˆì„ ì½ê¸° ì˜¤ë¥˜: {e}")
                time.sleep(0.1)
                continue
        else:
            ret, frame = cap.read()
            if not ret or frame is None:
                time.sleep(0.1)
                continue
        
        h_img, w_img = frame.shape[:2]
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # ì  ì¶”ì  (Optical Flow)
        if tracking_active and prev_gray is not None:
            new_points = track_points_optical_flow(prev_gray, gray, tracked_points)
            if new_points is not None:
                tracked_points = new_points
        
        prev_gray = gray.copy()
        
        # í˜„ì¬ ì‹œê°„
        current_time = time.time()
        
        # ìƒíƒœ í‘œì‹œ
        if not tracking_active:
            remaining = 3 - len(selected_points)
            cv2.putText(frame, f"Click to select points ({remaining} remaining)", 
                       (20, 30), FONT, 0.8, (0, 255, 255), 2)
            cv2.putText(frame, f"Z-axis distance: {FIXED_Z_DISTANCE*100:.1f}cm (fixed)", 
                       (20, 60), FONT, 0.6, (255, 255, 255), 2)
        else:
            cv2.putText(frame, "Tracking active - Move camera left/right", 
                       (20, 30), FONT, 0.7, (0, 255, 0), 2)
            cv2.putText(frame, f"Z-axis: {FIXED_Z_DISTANCE*100:.1f}cm (fixed)", 
                       (20, 60), FONT, 0.6, (255, 255, 255), 2)
            
            # ì¸¡ì • ìƒíƒœ í‘œì‹œ
            if measurement_active:
                cv2.putText(frame, f"[AUTO MEASURING] Recording every 1 sec ({len(measurement_log)} records)", 
                           (20, 90), FONT, 0.7, (0, 255, 0), 2)
                # ê¹œë°•ì´ëŠ” íš¨ê³¼ (ë…¹ìƒ‰)
                if int(current_time * 2) % 2 == 0:
                    cv2.circle(frame, (w_img - 30, 30), 15, (0, 255, 0), -1)
                    cv2.putText(frame, "REC", (w_img - 80, 40), FONT, 0.6, (0, 255, 0), 2)
                # ì €ì¥ ì•ˆë‚´
                cv2.putText(frame, "[Press 'S' to save data to CSV]", 
                           (20, 120), FONT, 0.6, (0, 255, 255), 2)
            else:
                cv2.putText(frame, "[Paused - Press 'M' to resume measuring]", 
                           (20, 90), FONT, 0.6, (0, 165, 255), 2)
            
            # ê·¸ë˜í”„ ìƒíƒœ í‘œì‹œ (ìœ„ì¹˜ ì¡°ì •)
            if graph_enabled:
                cv2.putText(frame, "[Graph: ON]", 
                           (20, 150), FONT, 0.5, (0, 255, 255), 1)
            else:
                cv2.putText(frame, "[Press 'G' for graph]", 
                           (20, 150), FONT, 0.5, (200, 200, 200), 1)
        
        # ì„ íƒëœ/ì¶”ì  ì¤‘ì¸ ì ë“¤ í‘œì‹œ ë° ê±°ë¦¬ ê³„ì‚°
        colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]
        
        # í˜„ì¬ í”„ë ˆì„ì˜ ì¸¡ì • ë°ì´í„° ì €ì¥ìš©
        current_measurements = []
        points_3d = []  # ì •ë ¬ ì¸¡ì •ìš© 3D ì¢Œí‘œ ë¦¬ìŠ¤íŠ¸
        
        for i in range(len(tracked_points)):
            point = tracked_points[i]
            color = colors[i]
            
            # ì  í‘œì‹œ
            cv2.circle(frame, (int(point[0]), int(point[1])), 10, color, -1)
            cv2.circle(frame, (int(point[0]), int(point[1])), 15, color, 2)
            cv2.putText(frame, point_names[i], 
                       (int(point[0]) + 20, int(point[1]) - 15), 
                       FONT, 0.6, color, 2)
            
            # ê±°ë¦¬ ê³„ì‚°
            result = calculate_3d_position_fixed_z(
                point, focal_length, FIXED_Z_DISTANCE, w_img, h_img
            )
            
            if result is not None:
                X, Y, Z, distance_3d = result
                
                # EMA í•„í„° ì ìš©
                if ema_distances[i] is None:
                    ema_distances[i] = distance_3d
                else:
                    ema_distances[i] = alpha * distance_3d + (1 - alpha) * ema_distances[i]
                
                # 3D ì¢Œí‘œ ì €ì¥ (ì •ë ¬ ì¸¡ì •ìš©)
                points_3d.append((X, Y, Z))
                
                # ì¸¡ì • ë°ì´í„° ì €ì¥
                current_measurements.append({
                    'X': X * 100,  # m â†’ cm
                    'Y': Y * 100,
                    'Z': Z * 100,
                    'distance': ema_distances[i] * 100
                })
                
                # í™”ë©´ì— í‘œì‹œ
                y_offset = 180 + i * 130
                cv2.putText(frame, f"=== {point_names[i]} ===", 
                           (20, y_offset), FONT, 0.7, color, 2)
                cv2.putText(frame, f"X: {X*100:+.2f}cm  Y: {Y*100:+.2f}cm  Z: {Z*100:.2f}cm", 
                           (20, y_offset + 30), FONT, 0.6, color, 1)
                cv2.putText(frame, f"Distance: {ema_distances[i]*100:.2f}cm ({ema_distances[i]*1000:.1f}mm)", 
                           (20, y_offset + 60), FONT, 0.7, color, 2)
                
                # ì´ˆê¸° ìœ„ì¹˜ë¡œë¶€í„°ì˜ ë³€í™”ëŸ‰
                if i < len(selected_points):
                    initial_point = selected_points[i]
                    dx = (point[0] - initial_point[0])
                    dy = (point[1] - initial_point[1])
                    cv2.putText(frame, f"Pixel shift: X{dx:+.0f}px Y{dy:+.0f}px", 
                               (20, y_offset + 90), FONT, 0.5, color, 1)
        
        # ê·¸ë˜í”„ ë°ì´í„° ì—…ë°ì´íŠ¸ (ê·¸ë˜í”„ê°€ í™œì„±í™”ëœ ê²½ìš°)
        if graph_enabled and len(tracked_points) == 3 and len(ema_distances) == 3:
            if all(d is not None for d in ema_distances):
                distances_cm = [d * 100 for d in ema_distances]  # m â†’ cm
                update_graph_data(distances_cm)
        
        # ì •ë ¬ ìƒíƒœ ì¸¡ì • ë° í‘œì‹œ
        if len(points_3d) == 3:
            alignment = calculate_alignment_metrics(points_3d)
            if alignment is not None:
                # ì •ë ¬ ìƒíƒœ í‘œì‹œ ì˜ì—­ (ì˜¤ë¥¸ìª½ ìƒë‹¨)
                align_x = w_img - 480
                align_y = 120
                
                # ë°°ê²½ ë°•ìŠ¤
                cv2.rectangle(frame, (align_x - 10, align_y - 30), 
                             (w_img - 10, align_y + 160), (0, 0, 0), -1)
                cv2.rectangle(frame, (align_x - 10, align_y - 30), 
                             (w_img - 10, align_y + 160), (255, 255, 255), 2)
                
                # ì œëª©
                cv2.putText(frame, "=== ALIGNMENT STATUS ===", 
                           (align_x, align_y), FONT, 0.7, (255, 255, 255), 2)
                
                # Zì¶• í¸ì°¨
                z_range_mm = alignment['z_range'] * 1000  # m â†’ mm
                z_color = (0, 255, 0) if z_range_mm < 1.0 else (0, 165, 255) if z_range_mm < 2.0 else (0, 0, 255)
                cv2.putText(frame, f"Z-axis range: {z_range_mm:.2f}mm", 
                           (align_x, align_y + 35), FONT, 0.6, z_color, 2)
                
                # ê³µì„ ì„±
                col_norm = alignment['collinearity_normalized']
                col_color = (0, 255, 0) if col_norm < 0.05 else (0, 165, 255) if col_norm < 0.1 else (0, 0, 255)
                cv2.putText(frame, f"Collinearity: {col_norm:.4f}", 
                           (align_x, align_y + 70), FONT, 0.6, col_color, 2)
                
                # ì •ë ¬ ìƒíƒœ
                if alignment['is_aligned']:
                    status_text = "ALIGNED!"
                    status_color = (0, 255, 0)
                    # ì²´í¬ ë§ˆí¬
                    cv2.circle(frame, (w_img - 50, align_y + 115), 20, (0, 255, 0), 3)
                    cv2.line(frame, (w_img - 58, align_y + 115), (w_img - 50, align_y + 123), (0, 255, 0), 3)
                    cv2.line(frame, (w_img - 50, align_y + 123), (w_img - 38, align_y + 105), (0, 255, 0), 3)
                else:
                    status_text = "NOT ALIGNED"
                    status_color = (0, 0, 255)
                    # X ë§ˆí¬
                    cv2.line(frame, (w_img - 65, align_y + 100), (w_img - 35, align_y + 130), (0, 0, 255), 3)
                    cv2.line(frame, (w_img - 35, align_y + 100), (w_img - 65, align_y + 130), (0, 0, 255), 3)
                
                cv2.putText(frame, status_text, 
                           (align_x, align_y + 120), FONT, 0.8, status_color, 2)
                
                # ê°€ì´ë“œ ë©”ì‹œì§€
                if not alignment['is_aligned']:
                    cv2.putText(frame, "Adjust motor positions", 
                               (align_x, align_y + 150), FONT, 0.5, (255, 200, 0), 1)
        
        # 1ì´ˆë§ˆë‹¤ ì¸¡ì • ê¸°ë¡
        if measurement_active and tracking_active and len(current_measurements) == 3:
            if current_time - last_measurement_time >= 1.0:
                timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                
                # ì •ë ¬ ì •ë³´ë„ í•¨ê»˜ ì €ì¥
                alignment_info = calculate_alignment_metrics(points_3d) if len(points_3d) == 3 else None
                
                measurement_log.append({
                    'timestamp': timestamp,
                    'points': current_measurements,
                    'alignment': alignment_info
                })
                last_measurement_time = current_time
                
                # ì½˜ì†” ì¶œë ¥ (ê°œì„ ëœ í¬ë§·)
                align_status = "âœ“ ALIGNED" if (alignment_info and alignment_info['is_aligned']) else "âœ— NOT ALIGNED"
                z_range_mm = alignment_info['z_range'] * 1000 if alignment_info else 0
                
                print(f"\n[ê¸°ë¡ #{len(measurement_log)}] {timestamp}")
                print(f"  Point 1: {current_measurements[0]['distance']:.2f}cm")
                print(f"  Point 2: {current_measurements[1]['distance']:.2f}cm")
                print(f"  Point 3: {current_measurements[2]['distance']:.2f}cm")
                print(f"  Z-range: {z_range_mm:.2f}mm | Status: {align_status}")
                print(f"  (ì´ {len(measurement_log)}ê°œ ì¸¡ì • ì™„ë£Œ, 's' í‚¤ë¡œ ì €ì¥)")
        
        # í™”ë©´ í‘œì‹œ
        cv2.imshow(window_name, frame)
        
        key = cv2.waitKey(1) & 0xFF
        
        if key == ord('q'):
            # ì¢…ë£Œ ì‹œ ì¸¡ì • ì¤‘ì´ì—ˆë‹¤ë©´ ìë™ ì €ì¥
            if measurement_log:
                print(f"\n[INFO] ì¢…ë£Œ ì „ ì¸¡ì • ë°ì´í„° ìë™ ì €ì¥ ì¤‘...")
                save_measurement_log()
            break
        elif key == ord('m') or key == ord('M'):
            # ì¸¡ì • ì‹œì‘/ì¤‘ì§€
            if tracking_active:
                measurement_active = not measurement_active
                if measurement_active:
                    last_measurement_time = current_time
                    print("\n" + "="*70)
                    print("[INFO] âœ“ ì¸¡ì • ì¬ê°œ - 1ì´ˆë§ˆë‹¤ ìë™ ê¸°ë¡ ì¤‘...")
                    print("="*70)
                else:
                    print("\n" + "="*70)
                    print(f"[INFO] â¸ ì¸¡ì • ì¼ì‹œì •ì§€ (í˜„ì¬ {len(measurement_log)}ê°œ ê¸°ë¡)")
                    print("      ë‹¤ì‹œ 'm' í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì¸¡ì •ì´ ì¬ê°œë©ë‹ˆë‹¤")
                    print("="*70)
            else:
                print("[WARNING] ë¨¼ì € 3ì ì„ ì„ íƒí•´ì£¼ì„¸ìš”!")
        elif key == ord('s') or key == ord('S'):
            # ì¸¡ì • ë°ì´í„° ì €ì¥
            save_measurement_log()
        elif key == ord('g') or key == ord('G'):
            # ì‹¤ì‹œê°„ ê·¸ë˜í”„ ì‹œì‘
            if tracking_active:
                start_graph_thread()
            else:
                print("[WARNING] ë¨¼ì € 3ì ì„ ì„ íƒí•´ì£¼ì„¸ìš”!")
        elif key == ord('r'):
            # ì´ˆê¸°í™”
            selected_points = []
            tracked_points = []
            tracking_active = False
            measurement_active = False
            ema_distances = [None, None, None]
            prev_gray = None
            print("\n" + "="*70)
            print("[INFO] ğŸ”„ ì  ì„ íƒ ì´ˆê¸°í™” ì™„ë£Œ")
            print("      ë‹¤ì‹œ ë§ˆìš°ìŠ¤ë¡œ 3ì ì„ í´ë¦­í•˜ì„¸ìš”")
            print("="*70)
        elif key == ord('z'):
            # Zì¶• ê±°ë¦¬ ì¬ì„¤ì •
            z_input = get_z_distance_input()
            if z_input is not None:
                FIXED_Z_DISTANCE = z_input
                print(f"[INFO] Zì¶• ê±°ë¦¬ ë³€ê²½: {FIXED_Z_DISTANCE*100:.1f}cm")
                # ê±°ë¦¬ ì¬ê³„ì‚°ì„ ìœ„í•´ EMA ì´ˆê¸°í™”
                ema_distances = [None, None, None]
    
    # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    if picam is not None:
        try:
            picam.stop()
            picam.close()
            print("[INFO] Raspberry Pi ì¹´ë©”ë¼ ì¢…ë£Œ")
        except:
            pass
    if cap is not None:
        cap.release()
        print("[INFO] USB ì¹´ë©”ë¼ ì¢…ë£Œ")
    cv2.destroyAllWindows()

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n[INFO] í”„ë¡œê·¸ë¨ì´ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\n[ERROR] ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    finally:
        cv2.destroyAllWindows()
        print("[INFO] í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
